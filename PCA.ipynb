{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAnalyzer():\n",
    "    def __init__(self,n_components):\n",
    "        self.n_components = n_components\n",
    "        \n",
    "    def fit(self, data):\n",
    "        # data of dimension (n_samples, n_features)\n",
    "        # Assuming n_samples > n_features (TODO: handle for the case of n_fatures <= n_samples)\n",
    "        self.mean = np.mean(data, axis=0)\n",
    "        self.covmat = np.cov(np.transpose(data))\n",
    "        self.lamda, self.U = np.linalg.eigh(self.covmat)\n",
    "        # Get eigen vectors and eigen values in eigen value descending order\n",
    "        idx = self.lamda.argsort()[::-1]\n",
    "        self.U = self.U[:,idx]\n",
    "        self.lamda = self.lamda[idx]\n",
    "        self.n_features = data.shape[1]\n",
    "    \n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)  \n",
    "    \n",
    "    def inverse_transform(self, transformed_data):\n",
    "        # Convert back to original coordinates\n",
    "        return np.transpose(np.matmul(self.U,np.transpose(transformed_data))+np.expand_dims(self.mean,1))\n",
    "    \n",
    "    def transform(self, data):\n",
    "        # P = U.t * (X.t-mean(X.t)) with only first n_components PC\n",
    "        return np.transpose(np.matmul(np.transpose(self.U), (np.transpose(data)-np.expand_dims(self.mean,1)))\n",
    "    *np.expand_dims(np.concatenate((np.ones(self.n_components),np.zeros(self.n_features-self.n_components))),1))\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_name(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read input data\n",
    "dataI = np.array(pd.read_csv(\"data\\dataI.csv\")[['X1','X2','X3','X4']])\n",
    "dataII = np.array(pd.read_csv(\"data\\dataII.csv\")[['X1','X2','X3','X4']])\n",
    "dataIII = np.array(pd.read_csv(\"data\\dataIII.csv\")[['X1','X2','X3','X4']])\n",
    "dataIV = np.array(pd.read_csv(\"data\\dataIV.csv\")[['X1','X2','X3','X4']])\n",
    "dataV = np.array(pd.read_csv(\"data\\dataV.csv\")[['X1','X2','X3','X4']])\n",
    "iris = np.array(pd.read_csv(\"data\\iris.csv\")[['Sepal.Length','Sepal.Width','Petal.Length','Petal.Width']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with iris data set -> mean square error of dataI with 1 PC: 0.6410931849009849\n",
      "Train with iris data set -> mean square error of dataII with 1 PC: 1.2903724507598\n",
      "Train with iris data set -> mean square error of dataIII with 1 PC: 0.7999427437338247\n",
      "Train with iris data set -> mean square error of dataIV with 1 PC: 1.917767749946061\n",
      "Train with iris data set -> mean square error of dataV with 1 PC: 0.38345031150498454\n",
      "Train with iris data set -> mean square error of dataI with 2 PC: 0.7156284875049558\n",
      "Train with iris data set -> mean square error of dataII with 2 PC: 1.9672403923798694\n",
      "Train with iris data set -> mean square error of dataIII with 2 PC: 0.8280825547067442\n",
      "Train with iris data set -> mean square error of dataIV with 2 PC: 3.331722103940333\n",
      "Train with iris data set -> mean square error of dataV with 2 PC: 0.1755630002443389\n",
      "Train with iris data set -> mean square error of dataI with 3 PC: 0.9083929073982754\n",
      "Train with iris data set -> mean square error of dataII with 3 PC: 2.650841135132735\n",
      "Train with iris data set -> mean square error of dataIII with 3 PC: 0.9849497682406688\n",
      "Train with iris data set -> mean square error of dataIV with 3 PC: 4.548257197249833\n",
      "Train with iris data set -> mean square error of dataV with 3 PC: 0.14178364800457013\n",
      "Train with iris data set -> mean square error of dataI with 4 PC: 1.1156578578493084\n",
      "Train with iris data set -> mean square error of dataII with 4 PC: 3.653279732511108\n",
      "Train with iris data set -> mean square error of dataIII with 4 PC: 1.1939999999999995\n",
      "Train with iris data set -> mean square error of dataIV with 4 PC: 5.139266666666666\n",
      "Train with iris data set -> mean square error of dataV with 4 PC: 0.1608383618076381\n",
      "Train with noisy data set -> mean square error of dataI with 1 PC: 0.6486421084108522\n",
      "Train with noisy data set -> mean square error of dataII with 1 PC: 1.3234621480418767\n",
      "Train with noisy data set -> mean square error of dataIII with 1 PC: 0.840614157257198\n",
      "Train with noisy data set -> mean square error of dataIV with 1 PC: 2.8356794280264346\n",
      "Train with noisy data set -> mean square error of dataV with 1 PC: 0.38461353395761755\n",
      "Train with noisy data set -> mean square error of dataI with 2 PC: 0.750621128999984\n",
      "Train with noisy data set -> mean square error of dataII with 2 PC: 2.119748049281955\n",
      "Train with noisy data set -> mean square error of dataIII with 2 PC: 1.2070897968259078\n",
      "Train with noisy data set -> mean square error of dataIV with 2 PC: 4.651434502717097\n",
      "Train with noisy data set -> mean square error of dataV with 2 PC: 0.17781528266962573\n",
      "Train with noisy data set -> mean square error of dataI with 3 PC: 0.9419728192850572\n",
      "Train with noisy data set -> mean square error of dataII with 3 PC: 3.0273799199753313\n",
      "Train with noisy data set -> mean square error of dataIII with 3 PC: 1.2711919671860714\n",
      "Train with noisy data set -> mean square error of dataIV with 3 PC: 4.971247271525605\n",
      "Train with noisy data set -> mean square error of dataV with 3 PC: 0.14444050603137715\n",
      "Train with noisy data set -> mean square error of dataI with 4 PC: 1.1156578578493088\n",
      "Train with noisy data set -> mean square error of dataII with 4 PC: 3.653279732511108\n",
      "Train with noisy data set -> mean square error of dataIII with 4 PC: 1.1940000000000002\n",
      "Train with noisy data set -> mean square error of dataIV with 4 PC: 5.139266666666673\n",
      "Train with noisy data set -> mean square error of dataV with 4 PC: 0.16083836180763808\n"
     ]
    }
   ],
   "source": [
    "for n in range(4):\n",
    "    pca_noiseless = PCAnalyzer(n+1)\n",
    "    pca_noiseless.fit(iris)\n",
    "    for data in (dataI, dataII, dataIII, dataIV, dataV):\n",
    "        data_name = array_name(data, globals())\n",
    "        mean_square_error = np.mean(np.sum((pca_noiseless.inverse_transform(pca_noiseless.transform(data)) - iris) ** 2,axis=1))\n",
    "        print(\"Train with iris data set -> mean square error of \" + data_name +\" with \"+str(n+1) +\" PC: \"+str(mean_square_error))\n",
    "\n",
    "for n in range(4):\n",
    "    pca_noisy = PCAnalyzer(n+1)\n",
    "    for data in (dataI, dataII, dataIII, dataIV, dataV):\n",
    "        data_name = array_name(data, globals())\n",
    "        mean_square_error = np.mean(np.sum((pca_noisy.inverse_transform(pca_noisy.fit_transform(data)) - iris) ** 2,axis=1))\n",
    "        print(\"Train with noisy data set -> mean square error of \" + data_name +\" with \"+str(n+1) +\" PC: \"+str(mean_square_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export 2PC for dataII\n",
    "pca_data2 = PCAnalyzer(2)\n",
    "\n",
    "X_hat = pca_data2.inverse_transform(pca_data2.fit_transform(data))\n",
    "np.savetxt(\"xl55-recon.csv\", np.transpose(X_hat), delimiter =',', header ='Sepal.Length,Sepal.Width,Petal.Length,Petal.Width',comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with iris data set -> mean square error of dataI with 1 PC: 0.6410931849009851\n",
      "Train with iris data set -> mean square error of dataII with 1 PC: 1.2903724507598011\n",
      "Train with iris data set -> mean square error of dataIII with 1 PC: 0.7999427437338249\n",
      "Train with iris data set -> mean square error of dataIV with 1 PC: 1.9177677499460624\n",
      "Train with iris data set -> mean square error of dataV with 1 PC: 0.3834503115049846\n",
      "Train with iris data set -> mean square error of dataI with 2 PC: 0.7156284875049566\n",
      "Train with iris data set -> mean square error of dataII with 2 PC: 1.9672403923798711\n",
      "Train with iris data set -> mean square error of dataIII with 2 PC: 0.8280825547067426\n",
      "Train with iris data set -> mean square error of dataIV with 2 PC: 3.3317221039403275\n",
      "Train with iris data set -> mean square error of dataV with 2 PC: 0.17556300024433896\n",
      "Train with iris data set -> mean square error of dataI with 3 PC: 0.9083929073982748\n",
      "Train with iris data set -> mean square error of dataII with 3 PC: 2.650841135132736\n",
      "Train with iris data set -> mean square error of dataIII with 3 PC: 0.9849497682406678\n",
      "Train with iris data set -> mean square error of dataIV with 3 PC: 4.548257197249828\n",
      "Train with iris data set -> mean square error of dataV with 3 PC: 0.14178364800457013\n",
      "Train with iris data set -> mean square error of dataI with 4 PC: 1.1156578578493086\n",
      "Train with iris data set -> mean square error of dataII with 4 PC: 3.6532797325111095\n",
      "Train with iris data set -> mean square error of dataIII with 4 PC: 1.1940000000000002\n",
      "Train with iris data set -> mean square error of dataIV with 4 PC: 5.139266666666668\n",
      "Train with iris data set -> mean square error of dataV with 4 PC: 0.16083836180763814\n",
      "Train with noisy data set -> mean square error of dataI with 1 PC: 0.6486421084108523\n",
      "Train with noisy data set -> mean square error of dataII with 1 PC: 1.3234621480418753\n",
      "Train with noisy data set -> mean square error of dataIII with 1 PC: 0.8406141572571983\n",
      "Train with noisy data set -> mean square error of dataIV with 1 PC: 2.8356794280264306\n",
      "Train with noisy data set -> mean square error of dataV with 1 PC: 0.38461353395761755\n",
      "Train with noisy data set -> mean square error of dataI with 2 PC: 0.7506211289999839\n",
      "Train with noisy data set -> mean square error of dataII with 2 PC: 2.1197480492819545\n",
      "Train with noisy data set -> mean square error of dataIII with 2 PC: 1.2070897968259078\n",
      "Train with noisy data set -> mean square error of dataIV with 2 PC: 4.651434502717086\n",
      "Train with noisy data set -> mean square error of dataV with 2 PC: 0.17781528266962573\n",
      "Train with noisy data set -> mean square error of dataI with 3 PC: 0.9419728192850569\n",
      "Train with noisy data set -> mean square error of dataII with 3 PC: 3.0273799199753313\n",
      "Train with noisy data set -> mean square error of dataIII with 3 PC: 1.2711919671860719\n",
      "Train with noisy data set -> mean square error of dataIV with 3 PC: 4.971247271525593\n",
      "Train with noisy data set -> mean square error of dataV with 3 PC: 0.1444405060313772\n",
      "Train with noisy data set -> mean square error of dataI with 4 PC: 1.1156578578493082\n",
      "Train with noisy data set -> mean square error of dataII with 4 PC: 3.653279732511108\n",
      "Train with noisy data set -> mean square error of dataIII with 4 PC: 1.1940000000000006\n",
      "Train with noisy data set -> mean square error of dataIV with 4 PC: 5.139266666666662\n",
      "Train with noisy data set -> mean square error of dataV with 4 PC: 0.1608383618076381\n"
     ]
    }
   ],
   "source": [
    "# Compare with sklearn PCA\n",
    "\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "for n in range(4):\n",
    "    pca_noiseless = PCA(n+1)\n",
    "    pca_noiseless.fit(iris)\n",
    "    for data in (dataI, dataII, dataIII, dataIV, dataV):\n",
    "        data_name = array_name(data, globals())\n",
    "        mean_square_error = np.mean(np.sum((pca_noiseless.inverse_transform(pca_noiseless.transform(data)) - iris) ** 2,axis=1))\n",
    "        print(\"Train with iris data set -> mean square error of \" + data_name +\" with \"+str(n+1) +\" PC: \"+str(mean_square_error))\n",
    "\n",
    "for n in range(4):\n",
    "    pca_noisy = PCA(n+1)\n",
    "    for data in (dataI, dataII, dataIII, dataIV, dataV):\n",
    "        data_name = array_name(data, globals())\n",
    "        mean_square_error = np.mean(np.sum((pca_noisy.inverse_transform(pca_noisy.fit_transform(data)) - iris) ** 2,axis=1))\n",
    "        print(\"Train with noisy data set -> mean square error of \" + data_name +\" with \"+str(n+1) +\" PC: \"+str(mean_square_error))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
